import gradio as gr
import requests
import soundfile as sf
import time
import torchaudio
import torch
import cfg
import tempfile
from flask import Flask, request, jsonify, Response
from pydub import AudioSegment

def chat_with_bot(user_audio,session_id):

    url = "http://localhost:8765/chat"
    sampling_rate, np_audio_data = user_audio
    audio_data = torch.tensor(np_audio_data, dtype=torch.float32).unsqueeze(0)
    filename = f'/tmp/{int(time.time())}.wav'
    torchaudio.save(filename, audio_data, sampling_rate)
    # å‘é€è¯·æ±‚ï¼Œå¹¶ç¡®ä¿è®¾ç½® stream=True æ¥è·å–æµå¼å“åº”
    response = requests.post(url, files={"audio": open(filename, "rb")}, data={"session_id": session_id}, stream=True)

    # if response.status_code == 200:
    print("å¼€å§‹æ¥æ”¶æµå¼æ•°æ®")
    i = 0
    format = "wav"
    # è¿­ä»£å“åº”çš„æµå¼å†…å®¹
    for chunk in response.iter_content(chunk_size=1024):  # æ‚¨å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´ chunk_size çš„å¤§å°
        if chunk:  # è¿‡æ»¤æ‰ä¿æ´»æ–°è¡Œ
            i += 1
            file_path = f"{tempfile.gettempdir()}/{i}.{format}"
            print(file_path)
            # ä½¿ç”¨ pydub å¤„ç†éŸ³é¢‘æ•°æ®
            segment = AudioSegment(chunk, frame_rate=32000, sample_width=2, channels=1)
            segment.export(file_path, format=format)
            yield file_path


with gr.Blocks(title='AI-XiaoXu') as demo:
    # ä½¿ç”¨ gr.HTML æ¥å®ç°å›¾ç‰‡å’Œæ–‡æœ¬çš„å±…ä¸­
    gr.HTML(value="""
    <div style='text-align: center;'>
        <img src='https://shengbucket.oss-cn-hangzhou.aliyuncs.com/files/xiaoxu2.png' style='display: block; margin-left: auto; margin-right: auto; max-width: 10%; height: auto;' />
        <h1>AI-XiaoXu (A Customer Service Robot)</h1>
        <h3>Danxiaoxu intelligent customer service robot internal demonstration and interactive system</h3>
        <h3>ç‰ˆæƒæ‰€æœ‰@é¾™å£ç§‘æŠ€</h3>
    </div>
    """)
    with gr.Row():
        init_message = cfg.start_text
        chatbot = gr.Chatbot(value=[("bot", init_message)])
    with gr.Column():
        with gr.Row():
            with gr.Column():
                session_id = gr.Textbox(visible=True, label="å¯¹è¯ID")
                gr.Markdown("è¯·ä¸Šä¼ æ‚¨çš„è¯­éŸ³æ–‡ä»¶")
                audio = gr.Audio()
            with gr.Column():
                gr.Markdown("æœºå™¨äººå›å¤")
                bot_response_audio = gr.Audio(value="init.wav",
                                              streaming=True,
                                              autoplay=True,
                                              interactive=False)
        with gr.Row():
            send_button = gr.Button("å‘é€ ğŸš€")
            clear_button = gr.Button("æ¸…é™¤ ğŸ’£")
        with gr.Row():
            qid = gr.Textbox(visible=False, label="qid")

            
    # def get_new_history():
    #     history_text = 

    def clear_chatbot():
        chatbot.value = []  # Clear chatbot history directly

    send_button.click(chat_with_bot, inputs=[audio,session_id], outputs=[bot_response_audio])
    clear_button.click(clear_chatbot, inputs=[], outputs=[chatbot])

demo.launch()
